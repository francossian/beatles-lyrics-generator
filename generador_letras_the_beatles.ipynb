{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "eLh8z_hEUCTY"
   },
   "outputs": [],
   "source": [
    "# Generador de letras de The Beatles en base a cadenas de Markov\n",
    "\n",
    "# Franco Guiragossian\n",
    "# franco@modeliz.ar\n",
    "\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "TR6uHGtBUbFm"
   },
   "outputs": [],
   "source": [
    "# Inicializamos diccionarios\n",
    "\n",
    "inicial = {} # Dict Inicial: Va a generar la primer palabra.\n",
    "prim_orden = {} # Dict de primer orden: Permite generar la segunda palabra dada la anterior.\n",
    "seg_orden = {} # Dict de segundo orden: Permite generar palabras dadas las dos palabras anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "LNP9na4yUelU"
   },
   "outputs": [],
   "source": [
    "# Función para remover puntuaciones\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "S0mbp9FPUk4o"
   },
   "outputs": [],
   "source": [
    "# Función para agregar una palabras a un diccionario\n",
    "\n",
    "def agregar_palabra(dicc, pal, idx):\n",
    "    # Los inputs son el diccionario, la palabra, y valor (índice)\n",
    "    if pal not in dicc:\n",
    "        dicc[pal] = []\n",
    "    dicc[pal].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "FoBDJVw3UrbE"
   },
   "outputs": [],
   "source": [
    "# Populamos los diccionarios en base a las letras, iterando renglón por renglón\n",
    "\n",
    "for line in open('lyrics.txt'):\n",
    "    # Tokenizamos: Separamos los renglones palabra por palabra en una lista\n",
    "    tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "    T = len(tokens)\n",
    "    if T == 1:\n",
    "        # Si el renglón tiene una sola palabra, saltamos a la próxima iteración:\n",
    "        continue\n",
    "    for i in range(T):\n",
    "        t = tokens[i]\n",
    "        if i == 0:\n",
    "            # Si es la primera palabra, la consideramos para el diccionario inicial\n",
    "            inicial[t] = inicial.get(t, 0.) + 1\n",
    "            # Defaultea en 0, ya que si una palabra no había sido observada antes, empieza a contarla sumando\n",
    "            # 1 a 0\n",
    "        else:\n",
    "            t_1 = tokens[i-1] # t_1 es la palabra precedente\n",
    "            if i == T - 1:\n",
    "                # Si es la última palabra, agrego token especial \"FIN\" para que\n",
    "                # el modelo pueda samplear el final de una oración\n",
    "                agregar_palabra(seg_orden, (t_1, t), 'FIN')\n",
    "            if i == 1:\n",
    "                # Si es la segunda palabra, agrego al diccionario de primer orden\n",
    "                agregar_palabra(prim_orden, t_1, t)\n",
    "            else:\n",
    "                # Si no, agrego al diccionario de segundo orden (en base a las dos palabras precedentes)\n",
    "                t_2 = tokens[i-2]\n",
    "                agregar_palabra(seg_orden, (t_2, t_1), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "dq98tbyWU7J5"
   },
   "outputs": [],
   "source": [
    "# Normalizamos las distribuciones\n",
    "total_inicial = sum(inicial.values())\n",
    "for t, c in inicial.items():\n",
    "    inicial[t] = c / total_inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gWr05mfxVBqH"
   },
   "outputs": [],
   "source": [
    "# Función para calcular probabilidades de cada palabra en base a las anteriores, en cada diccionario\n",
    "\n",
    "def calcular_p(ts):\n",
    "    d = {}\n",
    "    n = len(ts)\n",
    "    for t in ts:\n",
    "        d[t] = d.get(t, 0.) + 1\n",
    "    for t, c in d.items():\n",
    "        d[t] = c / n\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "rR-QfKjZVMTC"
   },
   "outputs": [],
   "source": [
    "for t_1, ts in prim_orden.items():\n",
    "    prim_orden[t_1] = calcular_p(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "HZC4AFs8VPZS"
   },
   "outputs": [],
   "source": [
    "for k, ts in seg_orden.items():\n",
    "    seg_orden[k] = calcular_p(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "oTSW8KwMVX8g"
   },
   "outputs": [],
   "source": [
    "# Función para tomar una muestra de una palabra\n",
    "\n",
    "def samplear_palabra(d):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for t, p in d.items():\n",
    "        cumulative += p\n",
    "        if p0 < cumulative:\n",
    "            return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "rgLEb5NoVeUW"
   },
   "outputs": [],
   "source": [
    "# Función para generar \"n\" renglones de texto basado en las letras de The Beatles\n",
    "\n",
    "def generar_texto(n=4):\n",
    "    for i in range(n):\n",
    "        sentence = []\n",
    "        w0 = samplear_palabra(inicial)\n",
    "        sentence.append(w0)\n",
    "        w1 = samplear_palabra(prim_orden[w0])\n",
    "        sentence.append(w1)\n",
    "        while True:\n",
    "            w2 = samplear_palabra(seg_orden[(w0, w1)])\n",
    "            if w2 == 'FIN':\n",
    "                # Si sampleo el token especial \"FIN\", termino el renglón\n",
    "                break\n",
    "            sentence.append(w2)\n",
    "            w0 = w1\n",
    "            w1 = w2\n",
    "        print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnkxngVlVn7q",
    "outputId": "1b4f58c3-f36e-41c3-a16d-da71e92b3a51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so come on baby dont care to hear from you\n",
      "then its far too late\n",
      "oh believe me darling\n",
      "gather round all you clowns\n"
     ]
    }
   ],
   "source": [
    "generar_texto(4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
